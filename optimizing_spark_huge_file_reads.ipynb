{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d4e2ef70-8e4c-4d14-8fbf-c8339c7207a0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4f57b0ab-4691-44f2-b5f7-8dc2ec4c4594",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark = (\n",
    "    SparkSession.builder.master(\"local[8]\").appName(\"Optimize File Reads\").getOrCreate()\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "0ccba2d2-c714-4a54-a5d8-bc27052344ce",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "04314385-b724-4231-918d-b8e9b2f2dd92",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "partition_size = spark.conf.get(\"spark.sql.files.maxPartitionBytes\").replace(\"b\", \"\")\n",
    "\n",
    "print(\n",
    "    f\"Partition size: {partition_size} in bytes & {int(partition_size)/1024/1024} in MB\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "65390073-c3e4-4a4f-a3a3-34cd0e62175a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "print(f\"Parallelism: {spark.sparkContext.defaultParallelism}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4f9d678a-47e2-42a4-ac6d-18db0cca0275",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "file_size = os.path.getsize(\"/Users/dipankarpal/Downloads/Combined_Flights_2019.csv\")\n",
    "\n",
    "print(\n",
    "    f\"\"\"\n",
    "itineraries.csv File size:\n",
    "    {file_size} in bytes\n",
    "    {file_size / 1024 / 1024} in MB\n",
    "    {file_size / 1024 / 1024 / 1024} in GB\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cc33d0d9-db42-4f3e-91ba-ef826ba121da",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "\n",
    "def get_time(func):\n",
    "    def inner_get_time():\n",
    "        start_time = time.time()\n",
    "        func()\n",
    "        end_time = time.time()\n",
    "        print(\"-\" * 80)\n",
    "        return f\"Execution time: {(end_time - start_time) * 10000} milliseconds\"\n",
    "\n",
    "    print(inner_get_time())\n",
    "    print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ff4c1821-b517-452f-9a05-ee8024ac4273",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@get_time\n",
    "def df_func():\n",
    "    df = (\n",
    "        spark.read.option(\"header\", True)\n",
    "        .option(\"inferSchema\", True)\n",
    "        .csv(\"/Users/dipankarpal/Downloads/Combined_Flights_2019.csv\")\n",
    "    )\n",
    "\n",
    "    print(f\"Number of Partitions: {df.rdd.getNumPartitions()}\")\n",
    "\n",
    "    df.write.format(\"noop\").mode(\"overwrite\").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "80da4576-49fc-48a8-905a-31d06e18d71d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.files.maxPartitionBytes\", f\"{128 * 3 * 1024 * 1024}b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4309f9fc-0d5c-478a-886a-ee22b970a12a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "partition_size = spark.conf.get(\"spark.sql.files.maxPartitionBytes\").replace(\"b\", \"\")\n",
    "\n",
    "print(\n",
    "    f\"Partition size: {partition_size} in bytes & {int(partition_size)/1024/1024} in MB\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "8145a73c-cf04-4b52-90a2-e10588e144d7",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@get_time\n",
    "def df_func():\n",
    "    df = (\n",
    "        spark.read.option(\"header\", True)\n",
    "        .option(\"inferSchema\", True)\n",
    "        .csv(\"/Users/dipankarpal/Downloads/Combined_Flights_2019.csv\")\n",
    "    )\n",
    "\n",
    "    print(f\"Number of Partitions: {df.rdd.getNumPartitions()}\")\n",
    "\n",
    "    df.write.format(\"noop\").mode(\"overwrite\").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "a2d5fc86-82a9-470c-8d48-8a1648625bf0",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.files.maxPartitionBytes\", f\"{160 * 1024 * 1024}b\")\n",
    "\n",
    "partition_size = spark.conf.get(\"spark.sql.files.maxPartitionBytes\").replace(\"b\", \"\")\n",
    "\n",
    "print(\n",
    "    f\"Partition size: {partition_size} in bytes & {int(partition_size)/1024/1024} in MB\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "89d978a2-d77c-4cb0-8931-f27eae294d18",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@get_time\n",
    "def df_func():\n",
    "    df = (\n",
    "        spark.read.option(\"header\", True)\n",
    "        .option(\"inferSchema\", True)\n",
    "        .csv(\"/Users/dipankarpal/Downloads/Combined_Flights_2019.csv\")\n",
    "    )\n",
    "\n",
    "    print(f\"Number of Partitions: {df.rdd.getNumPartitions()}\")\n",
    "\n",
    "    df.write.format(\"noop\").mode(\"overwrite\").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "379e8f8e-b52e-4649-9c74-7b56195fbbbc",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.files.maxPartitionBytes\", f\"{178 * 1024 * 1024}b\")\n",
    "\n",
    "partition_size = spark.conf.get(\"spark.sql.files.maxPartitionBytes\").replace(\"b\", \"\")\n",
    "\n",
    "print(\n",
    "    f\"Partition size: {partition_size} in bytes & {int(partition_size)/1024/1024} in MB\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "67667cf8-0e89-4b7c-9375-69e49b55755c",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "@get_time\n",
    "def df_func():\n",
    "    df = (\n",
    "        spark.read.option(\"header\", True)\n",
    "        .option(\"inferSchema\", True)\n",
    "        .csv(\"/Users/dipankarpal/Downloads/Combined_Flights_2019.csv\")\n",
    "    )\n",
    "\n",
    "    print(f\"Number of Partitions: {df.rdd.getNumPartitions()}\")\n",
    "\n",
    "    df.write.format(\"noop\").mode(\"overwrite\").save()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "68d4c54e-d561-4183-b6a0-738c82233d93",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "optimizing_spark_huge_file_reads",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
